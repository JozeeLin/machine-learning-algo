# 第四章 朴素贝叶斯法

朴素贝叶斯法是基于贝叶斯原理与特征条件独立假设的分类方法.对于给定训练数据集,首先基于特征条件独立假设学习输入/输出的联合概率分布;然后基于此模型,对给定的输入x,**利用贝叶斯定理求出后验概率最大的输出y**.

朴素贝叶斯法属于**生成模型**.

> 朴素贝叶斯法和贝叶斯估计是不同的概念.

## 朴素贝叶斯法的学习与分类

P(X,Y)是X和Y的联合概率分布,而训练集是由P(X,Y)独立同分布产生.因此朴素贝叶斯法就是通过训练集来学习出P(X,Y)联合概率分布.它需要先分别求出先验概率分布及条件概率分布.

先验概率分布:
$$
P(Y=c_k) , k=1,2,...,K
$$
条件概率分布:
$$
P(X=x|Y=c_k)=P(X^1=x^1,...X^n=x^n|Y=c_k),k=1,2,...,K
$$
条件概率分布有指数级数量的参数,其估计实际上是不可行的.设$x^j$的可能取值的数目为$S_j$,则参数个数为:$K\prod_j^n S_j$.

因此,**朴素贝叶斯对条件概率分布做了条件独立性的假设**.具体的,条件独立假设是:
$$
\begin{aligned}
P(X=x|Y=c_k) &= P(X^1=x^1,...,X^n=x^n|Y=c_k) \\
&= \prod_{j=1}^nP(X^j=x^j|Y=c_k)
\end{aligned}
$$

> 条件独立假设等于说用于分类的特征在类确定的条件下都是条件独立的.

### 朴素贝叶斯法预测分类的思想(后验概率最大化)

朴素贝叶斯法分类时,对给定的输入x,通过学习到的模型计算后验概率分布$P(Y=c_k|X=x)$,将后验概率最大的类作为x的类输出,**后验概率计算根据贝叶斯定理**进行:
$$
P(Y=c_k|X=x) = \frac{P(X=x|Y=c_k)P(Y=c_k)}{\sum_k P(X=x|Y=c_k)P(Y=c_k)}
$$
根据条件概率中提出的条件独立性的假设,后验概率计算演变成:
$$
P(Y=c_k|X=x) = \frac{P(Y=c_k)\prod_jP(X^j=x^j|Y=c_k)}{\sum_k P(Y=c_k)\prod_jP(X^j=x^j|Y=c_k)}
$$
于是,朴素贝叶斯分类器可表示为:
$$
y = f(x) = \arg \max_{c_k} \frac{P(Y=c_k)\prod_jP(X^j=x^j|Y=c_k)}{\sum_k P(Y=c_k)\prod_jP(X^j=x^j|Y=c_k)}
$$
注意上式中的分母,对应任何的$c_k$取值都是一样的,所以上式可以简化为:
$$
y = \arg \max_{c_k} P(Y=c_k)\prod_{j=1}^nP(X^j=x^j|Y=c_k)
$$

### 后验概率最大化的含义

> 朴素贝叶斯法将实例分到后验概率最大的类中,这等价于期望风险最小化.

## 朴素贝叶斯的参数估计(计算先验概率和条件概率)

### 极大似然估计

在朴素贝叶斯法中,学习意味着估计$P(X=x|Y=c_k)$,$P(Y=c_k)$.**可以应用极大似然估计法估计相应的概率**.

输入:训练集有N个实例,特征向量维度为n,有K个标签数.

输出:给定实例x,输出它的分类

1.计算先验概率及条件概率

**先验概率:**
$$
P(Y=c_k) = \frac{\sum_{i=1}^{N}I(y_i=c_k)}{N} , k=1,2,...,K
$$
**条件概率:**
$$
P(X^j=a_{jl}|Y=c_k) = \frac{\sum_{i=1}^{N}I(x_i^j=a_{jl},y_i=c_k)}{\sum_{i=1}^N I(y_i=c_k)} \\
j=1,2,...,n;l=1,2,...,S_j;k=1,2,...,K
$$
2.对于给定实例$x=(x^1,x^2,...,x^n)^T$,计算它对应的后验概率:
$$
P(Y=c_k)\prod_{j=1}^nP(X^j=x^j|Y=c_k)
$$
3.通过最大化后验概率分布计算出使得后验概率最大的$c_k$:
$$
y = \arg \max_{c_k} P(Y=c_k)\prod_{j=1}^nP(X^j=x^j|Y=c_k)
$$

### 贝叶斯估计

用极大似然估计可能会出现所要估计的概率值为0的情况.**解决这一问题的方法是采用贝叶斯估计**.具体地,条件概率的贝叶斯估计是:
$$
P_\lambda(X^j=a_{jl}|Y=c_k) = \frac{\sum_{i=1}^N I(x_i^j=a_{jl},y_i=c_k)+\lambda}{\sum_{i=1}^N I(y_i=c_k)+S_j\lambda} , k=1,2,...,K
$$
式中$\lambda \geq 0$,等价于在随机变量各个取值的频数上赋予一个正数$\lambda>0$.**当$\lambda=0$时,就是极大似然估计**.**$\lambda=1$,这时称为拉普拉斯平滑**($\lambda$经常取的值为1).

## 延伸阅读

如果假设它们之间存在概率相关性,模型就变成了贝叶斯网络.
