## 罗森布拉特感知器

### 原理

1. 假设函数为$z = W^TX $ ， $ W=[w_0,w_1,w_2,...,w_m] \ X=[1,x_1,x_2,...,x_m]$ ($-w_0表示阈值$)

2. 激励函数为$\phi(z)$，如果$z>=0$，则$\phi(z)=1$，否则为-1。

3. 感知器的学习算法步骤如下：

   - 将权重初始化为0或一个极小的随机数

   - 迭代所有训练样本$X_i​$，执行如下操作：

     - 计算输出值$\hat{y}$（也就是激励函数返回的值）
     - 更新权重

     $$
     w_j := w_J+\Delta w_j  \\
     \Delta w_j = \eta(y^i-\hat{y^i})x_j^i \ ， （\eta为学习速率）
     $$

     所以预测错误的情况下，会趋向正确的方向(算法收敛的方向)。

     > 注意：感知器收敛的前提是两个类别必须线性可分的，且学习速率足够小(如果线性可分的情况下，学习率影响不大，但是如果是非线性可分的情况下，应该足够小，这样可以更加可能找到尽可能少的误分类数的划分方式)。否则，需要设定迭代次数最大值，或设置一个允许错误分类样本数量的阈值——否则，感知器训练会一直更新权值。

4. 综述：输入样本，计算出样本对应的假设函数的值，通过激励函数比较假设函数的值跟阈值之间大小来判断该样本是正样本还是负样本，同时把激励函数预测出来的结果跟实际观测的结果比较，如果分类错误，就对权值进行更新，否则不需要更新。一直迭代这些过程，直到错误分类样本的数量为0。所以，如果两个类别不是线性可分的话，同时不设置额外的限制条件，算法会一直迭代下去，造成堆栈溢出。


